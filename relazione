\documentclass[a4paper,12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{fancyhdr}
\usepackage{tocloft}
\geometry{margin=2.5cm}

% Numerazione sezioni e sottosezioni
\renewcommand{\thesection}{\thechapter.\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}
\setcounter{secnumdepth}{2}
\setcounter{tocdepth}{2}

% Font per sezioni
\titleformat{\section}
  {\normalfont\small\bfseries}
  {\thesection}{1em}{}

\titleformat{\subsection}
  {\normalfont\small\itshape}
  {\thesubsection}{1em}{}

\begin{document}

% --- Copertina ---
\begin{titlepage}
    \begin{center}
        \includegraphics[width=0.4\textwidth]{logo-universita.png}
        \Large\textbf{UNIVERSIT\`A DEGLI STUDI DI CATANIA}\\[0.3cm]
        \large Dipartimento di Matematica e Informatica\\
        \large Corso di Laurea Triennale in Informatica\\[2cm]

        \vspace{2cm}

        {\Huge \textbf{VolleyLive}}\\[0.5cm]
        {\large Sistema di monitoraggio, analisi e visualizzazione\\
        delle partite di pallavolo in tempo reale}\\[2.5cm]

        \vspace{1cm}

        \begin{flushleft}
            \textbf{Studente:} \\
            Claudio Nuncibello
        \end{flushleft}

        \vspace{1cm}

        \begin{flushright}
            \textbf{Relatore:} \\
            Prof. Salvatore Nicotra
        \end{flushright}

        \vfill

        \textbf{Anno Accademico 2024/2025}
    \end{center}
\end{titlepage}

% --- Abstract e logo ---
\newpage
\thispagestyle{empty}
\vspace*{2cm}
\begin{center}
    \includegraphics[width=0.4\textwidth]{volleylive-logo.png} \\[1.5cm]
    \textbf{\LARGE Abstract} \\[1cm]
    \begin{minipage}{0.85\textwidth}
        \small
        Il progetto \textbf{VolleyLive} nasce con l’obiettivo di monitorare e analizzare in tempo reale le partite di pallavolo, combinando tecnologie moderne per la gestione dei dati in streaming e la visualizzazione interattiva. Il sistema raccoglie snapshot live da API sportive, li trasforma e li distribuisce tramite una pipeline composta da Kafka, Logstash, Spark ed Elasticsearch. I dati vengono visualizzati in una dashboard frontend sviluppata in Next.js, offrendo funzionalit\`a come la selezione dei match preferiti e l’analisi predittiva dell’esito delle partite. L’intero progetto \`e containerizzato tramite Docker e supporta l’estensibilit\`a verso nuovi modelli e sport. Questa tesi descrive l’architettura, le scelte progettuali, e i risultati ottenuti attraverso l’implementazione del sistema.
    \end{minipage}
\end{center}
\newpage

% --- Indice ---
\tableofcontents
\newpage

% ===============================
% INTRODUZIONE
% ===============================
\chapter*{Introduzione}
\addtocontents{toc}{\vspace{0.3cm}\textbf{Introduzione}\par}

Il presente elaborato descrive lo sviluppo di \textbf{VolleyLive}, un sistema per il monitoraggio e l’analisi in tempo reale delle partite di pallavolo. Il progetto nasce in un contesto in cui l’ambito dell’analisi sportiva sta vivendo una profonda trasformazione, favorita dalla crescente disponibilità di dati e dall’utilizzo di tecnologie per l’elaborazione in streaming. L’integrazione di API sportive, strumenti di monitoraggio e algoritmi analitici consente oggi non solo di osservare lo svolgimento di una competizione, ma anche di interpretarne dinamicamente l’andamento e prevederne l’evoluzione. L’analisi in tempo reale ha assunto un ruolo centrale in numerosi ambiti applicativi, dallo sport professionale alla logistica industriale. Nel mondo sportivo, tuttavia, strumenti avanzati di elaborazione live sono spesso riservati a discipline molto seguite (come calcio o basket), o a contesti professionali ad alto budget. Per molte altre discipline, come la pallavolo, esistono margini significativi per migliorare l’accessibilità e la fruibilità dei dati durante gli eventi. VolleyLive non si propone soltanto come una soluzione funzionale per il monitoraggio in tempo reale, ma getta le basi per un sistema estensibile e orientato al futuro delle competizioni sportive. Grazie all’adozione di tecnologie scalabili e open source, la piattaforma si presta a essere ampliata per integrare nuove fonti dati e modelli predittivi sempre più sofisticati. In questo senso, VolleyLive rappresenta una prima esplorazione concreta verso sistemi intelligenti di supporto all’analisi sportiva, potenzialmente applicabili non solo alla pallavolo ma a molte altre discipline. Il sistema adotta tecnologie moderne come Kafka per la gestione del flusso dati, Logstash per la trasformazione degli eventi, Spark per l’elaborazione in tempo reale, Elasticsearch per l’indicizzazione e la consultazione, e una web app per la visualizzazione lato utente. Il tutto è orchestrato tramite container Docker, in modo da garantire portabilità, isolamento e semplicità di gestione. Gli obiettivi principali del progetto sono: \begin{itemize} \item costruire una pipeline dati solida e scalabile, in grado di gestire flussi continui di snapshot aggiornati ogni dieci secondi; \item applicare modelli di analisi per stimare in tempo reale l’esito delle partite in corso; \item offrire un’interfaccia intuitiva e interattiva per la consultazione live dei match. \item garantire la tracciabilità storica dei dati raccolti, utile per analisi retrospettive e sviluppo futuro di modelli predittivi più avanzati. \end{itemize} Dal punto di vista applicativo, VolleyLive è pensato per essere utilizzato sia da utenti generici interessati a seguire una competizione, sia da figure più tecniche come data analyst sportivi o scout che necessitano di uno strumento semplice ma flessibile per leggere, filtrare e confrontare partite in tempo reale. La tesi è articolata in sette capitoli. Dopo l’introduzione, il secondo capitolo descrive l’architettura generale del sistema e i componenti principali, soffermandosi sulle tecnologie adottate e sul loro ruolo nella pipeline. Il terzo capitolo approfondisce il funzionamento della raccolta dati live tramite API, mentre il quarto illustra i meccanismi di ingestione, trasformazione ed elaborazione in streaming. Il quinto capitolo è dedicato alla visualizzazione e all’interazione tramite dashboard web. Il sesto capitolo presenta una serie di risultati ottenuti attraverso l’esecuzione del sistema, evidenziando esempi pratici e scenari d’uso. Infine, il settimo capitolo raccoglie le riflessioni conclusive e suggerisce direzioni per futuri sviluppi ed estensioni. VolleyLive si propone quindi come una base concreta per sperimentare tecnologie moderne per lo streaming e l’analisi dei dati sportivi, ponendo particolare attenzione all’affidabilità del flusso, alla chiarezza della visualizzazione e alla possibilità di estensione verso altri sport o contesti analitici.

% ===============================
% CAPITOLO 1 - Architettura
% ===============================

\chapter{Architettura Generale del Sistema}

Il sistema \textbf{VolleyLive} è stato concepito e realizzato seguendo un approccio modulare e scalabile, con l’obiettivo di garantire affidabilità, continuità del flusso dati e facilità di estensione. Questo capitolo descrive nel dettaglio l’architettura generale adottata, soffermandosi su ciascuna delle tecnologie impiegate, sul ruolo che ricoprono nella pipeline e sulle relazioni tra i vari moduli.


\section{Panoramica dei Componenti Tecnologici}

In questa sezione si fornisce una descrizione dettagliata dei principali componenti tecnologici che costituiscono il sistema \textbf{VolleyLive}, evidenziando il ruolo operativo di ciascun modulo all’interno della pipeline. Ogni tecnologia è presentata nel contesto del suo impiego pratico, illustrandone le funzionalità chiave e le modalità con cui interagisce con gli altri elementi del sistema.


\subsection{Fonte Dati: SportDevs API}

Il sistema \textbf{VolleyLive} si basa sui dati forniti dalle API pubbliche di SportDevs, che rappresentano la fonte principale per l’acquisizione delle informazioni relative alle partite in corso. Queste API espongono una serie di endpoint REST, interrogabili in formato \texttt{JSON}, attraverso cui è possibile ottenere dati grezzi aggiornati sulle partite live, dai quali il sistema costruisce, tramite successive trasformazioni, snapshot strutturati e coerenti, idonei a essere impiegati nei modelli di previsione.

Nel flusso di sistema, le API costituiscono il punto iniziale della pipeline: i dati vengono estratti regolarmente dallo script \textit{producer}, che li interroga ogni dieci secondi. I dati ricevuti vengono normalizzati e strutturati per essere inoltrati a Kafka nel formato previsto. L'accesso avviene tramite chiave API e richiede attenzione nella gestione della frequenza di interrogazione per evitare di superare i limiti imposti dal servizio.

Nonostante l’ampia copertura e il buon livello di dettaglio, le API presentano alcune limitazioni. In particolare, durante le partite di campionati minori si riscontrano occasionali ritardi nell’aggiornamento dei punteggi, e la gestione del set di \textit{tiebreak} può risultare imprecisa o mancante. Queste problematiche sono note e, al momento, vengono gestite a livello applicativo convivendo con le possibili incongruenze nel dato.

Nel complesso, SportDevs rappresenta una soluzione efficace per alimentare in tempo reale il sistema \textbf{VolleyLive}, pur richiedendo l’adozione di logiche resilienti in fase di raccolta e validazione dei dati.

\subsection{Elaborazione e Normalizzazione: Logstash}

\textbf{Logstash} è il primo componente della pipeline incaricato della trasformazione dei dati in arrivo dalle API di \textbf{SportDevs}. Riceve direttamente i dati grezzi forniti dallo script Python (producer), li interpreta e li converte in un formato strutturato, adatto alla successiva pubblicazione su \textbf{Kafka}.

Le operazioni svolte da Logstash includono la normalizzazione dei nomi dei campi, l’estrazione di \textit{timestamp} coerenti, la gestione di dati opzionali o incoerenti, e l’aggiunta di metadati utili (come gli identificativi univoci del match). Queste trasformazioni avvengono tramite pipeline configurabili in formato dichiarativo, che permettono di adattare con facilità le regole di parsing e filtraggio.

Una volta completata l’elaborazione, Logstash pubblica gli \textit{snapshot} trasformati su un \textit{topic} Kafka, rendendoli disponibili per le successive fasi di analisi e indicizzazione. In questo modo, Logstash funge da punto di ingresso intelligente per il flusso dati del sistema, garantendo uniformità e qualità nella base informativa di \textbf{VolleyLive}.


\subsection{Gestione del Flusso Dati: Kafka}

\textbf{Apache Kafka} è il sistema di messaggistica distribuito adottato da \textbf{VolleyLive} per la gestione affidabile e scalabile del flusso dati in tempo reale. All’interno dell’architettura, Kafka riceve i dati già trasformati da \textbf{Logstash} e li rende disponibili per i successivi moduli di analisi e indicizzazione.

Ogni \textit{snapshot} elaborato viene pubblicato su un \textit{topic} Kafka, da cui può essere consumato in parallelo da più servizi, come \textbf{Apache Spark} o eventuali altri moduli analitici. Questo modello basato su pubblicazione e sottoscrizione (\textit{pub/sub}) consente un’elaborazione asincrona, modulare e facilmente estendibile.

La scelta di utilizzare Kafka è stata motivata dalla necessità di gestire un flusso continuo di eventi con frequenti aggiornamenti, mantenendo elevate garanzie di durabilità, ordinamento e possibilità di \textit{replay} dei messaggi. La sua architettura nativamente distribuita lo rende particolarmente adatto a scenari \textit{real-time} come quello di \textbf{VolleyLive}.


\subsection{Analisi Streaming: Apache Spark}

\textbf{Apache Spark} è il componente dedicato all’elaborazione avanzata dei dati in streaming nel sistema \textbf{VolleyLive}. Dopo che gli \textit{snapshot} sono stati pubblicati su Kafka da \textbf{Logstash}, Spark li consuma in tempo reale per applicare logiche analitiche e generare output destinati all’indicizzazione.

L’implementazione sfrutta \textbf{Spark Structured Streaming}, un sistema che elabora i dati in tempo reale suddividendoli in piccoli blocchi temporali (\textit{micro-batch}). Anche se i dati arrivano in modo continuo, Spark li raggruppa ogni pochi secondi e li processa in modo ordinato e affidabile. Questo approccio garantisce una \textit{semantica end-to-end}, ovvero l’elaborazione completa, senza perdite o duplicazioni, di ogni blocco di dati dall’ingresso all’output finale.

Nel contesto di VolleyLive, Spark viene utilizzato per applicare filtri, trasformazioni strutturali e, in prospettiva, funzioni di analisi predittiva basate su modelli di \textit{machine learning}.

Spark si colloca tra la distribuzione dei dati (Kafka) e la fase di visualizzazione (Elasticsearch), fungendo da nodo di elaborazione intermedio. Questa configurazione permette di isolare la logica analitica dal resto della pipeline, semplificando l’estensione futura del sistema verso algoritmi più sofisticati.


\subsection{Indicizzazione e Ricerca: Elasticsearch}

\textbf{Elasticsearch} è il motore di ricerca e indicizzazione adottato nel sistema \textbf{VolleyLive} per rendere interrogabili e visualizzabili gli \textit{snapshot} elaborati in tempo reale. Dopo l’elaborazione su \textbf{Apache Spark}, ogni snapshot viene inviato a Elasticsearch, dove viene memorizzato come documento JSON strutturato.

Tutti i dati, inclusi gli score predittivi e le informazioni live, vengono inseriti all’interno di un unico indice. Questa scelta progettuale consente di ottenere, tramite una singola query, tutte le informazioni aggiornate relative a un match, semplificando l’accesso lato frontend e migliorando l’efficienza delle chiamate.

L’indice è configurato con un \textit{mapping} coerente, che definisce esplicitamente la struttura e i tipi dei campi per garantire interrogazioni affidabili e prestazioni ottimali. Questo approccio assicura una base dati consistente e facilmente estendibile anche in fase di evoluzione del sistema.

Infine, per attività di \textit{debugging}, monitoraggio e ispezione manuale dei dati, il sistema fa uso di \textbf{Kibana}, uno strumento di visualizzazione integrato con Elasticsearch, utile in particolare durante le fasi di sviluppo.


\subsection{Visualizzazione: Frontend React/Next.js}

L’interfaccia utente di \textbf{VolleyLive} è sviluppata utilizzando il framework \textbf{React} in combinazione con \textbf{Next.js}, una soluzione moderna e performante per la realizzazione di applicazioni web dinamiche. Il frontend fornisce agli utenti una dashboard interattiva e reattiva per consultare lo stato in tempo reale delle partite, visualizzare punteggi, set e score predittivi.

Per accedere ai dati, il frontend comunica con un backend intermedio realizzato in \textbf{FastAPI}. Questo backend funge da strato di accesso alle informazioni archiviate in \textbf{Elasticsearch}, esponendo API REST personalizzate per effettuare query sui match live. Tale approccio consente di mantenere il database isolato, migliorare la sicurezza e semplificare la gestione delle richieste dal lato client.

La struttura della dashboard permette agli utenti di selezionare match preferiti live e visualizzare in dettaglio l’andamento di ciascun incontro. L’interfaccia è stata progettata per adattarsi ai diversi dispositivi.

Il frontend è containerizzato e integrato nell’infrastruttura tramite \textbf{Docker}, in modo da garantire coerenza tra ambiente di sviluppo e produzione e facilitare il deployment del sistema completo.


\subsection{Containerizzazione: Docker e Visualizzazione dell’Architettura}

Il sistema \textbf{VolleyLive} adotta una configurazione interamente containerizzata, implementata tramite \textbf{Docker}, al fine di garantire portabilità, isolamento e semplicità di gestione in tutte le fasi del ciclo di vita dell’applicazione. Ogni componente è incapsulato in un container indipendente, facilitando la manutenzione, il testing e il deployment multiambiente.

L’infrastruttura è orchestrata mediante \texttt{docker-compose}, che consente di avviare l’intero ecosistema tramite un’unica configurazione centralizzata. I servizi comunicano all’interno di una rete virtuale definita da Docker, riducendo le dipendenze esterne e i problemi di configurazione ambientale.

Tutti i moduli descritti nei paragrafi precedenti – inclusi il \textit{producer} Python, i servizi di elaborazione e analisi, l’API backend e l’interfaccia web – sono containerizzati e integrati nell’infrastruttura, assicurando coerenza tra ambiente di sviluppo e produzione.

Lo schema architetturale riportato in Figura~\ref{fig:architettura} illustra il flusso dei dati e le interazioni principali tra i servizi, dalla raccolta degli snapshot fino alla visualizzazione finale.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{schema-architettura.png}
    \caption{Architettura containerizzata del sistema VolleyLive}
    \label{fig:architettura}
\end{figure}


\section{Scelte Progettuali e Motivazioni}

La definizione dell’architettura di VolleyLive è frutto di un processo decisionale che ha bilanciato esigenze di efficienza, semplicità operativa e finalità analitiche.
In questa sezione vengono descritte le principali alternative valutate e le motivazioni che hanno portato alla definizione dell’architettura presentata nel paragrafo precedente.

\subsection{Pipeline Always-On vs On-Demand: Analisi Comparativa}

Nel progettare il sistema \textbf{VolleyLive}, si è valutata la possibilità di attivare la pipeline dati solo in risposta a un’azione dell’utente (approccio \textit{on-demand}) oppure di mantenerla costantemente attiva (approccio \textit{always-on}). La modalità \textit{on-demand}, sebbene più leggera dal punto di vista computazionale, avrebbe comportato una latenza iniziale, una complessità maggiore nel coordinamento tra moduli e una perdita della continuità storica. L’approccio \textit{always-on} garantisce invece un flusso costante e affidabile di dati, semplificando il design complessivo e consentendo l’elaborazione in tempo reale anche in assenza di richieste attive.

\subsection{Motivazioni della Scelta dell’Architettura Always-On}

L’adozione dell’architettura \textit{always-on} è stata guidata da due esigenze fondamentali: da un lato, garantire l’affidabilità e la continuità del flusso dati; dall’altro, costruire una base dati storica che consenta analisi retrospettive e l’applicazione di modelli predittivi. Inoltre, la natura del progetto – focalizzato sull’utilizzo di tecnologie di data streaming e containerizzazione – trova piena espressione in un sistema sempre attivo, che riflette in modo coerente gli obiettivi sperimentali della tesi.


% ===============================
% CAPITOLO 2 - Pipeline dei Dati Live
% ===============================

\chapter{Pipeline dei Dati Live}

\section{Snapshot Live: Struttura e Producer Python}
% Testo da inserire

\section{Produzione Dati su Kafka}
% Testo da inserire

\section{Tracciabilit\`a e Gestione dello Storico}
% Testo da inserire


% ===============================
% CAPITOLO 3 - Data Ingestion e Analisi
% ===============================

\chapter{Data Ingestion e Analisi Streaming}

\section{Parsing e Trasformazione con Logstash}
% Testo da inserire

\section{Storage e Indicizzazione in Elasticsearch}
% Testo da inserire

\section{Analisi Streaming con Spark}
% Testo da inserire

\section{Feature e Score Predittivi}
% Testo da inserire


% ===============================
% CAPITOLO 4 - Frontend
% ===============================

\chapter{Visualizzazione e Interfaccia Utente}

\section{Struttura della Dashboard}
% Testo da inserire

\section{Sistema dei Preferiti e Interazione Utente}
% Testo da inserire

\section{Tecnologie Web Adottate}
% Testo da inserire


% ===============================
% CAPITOLO 5 - Risultati
% ===============================

\chapter{Esecuzione del Sistema e Risultati Osservati}

\section{Snapshot e Ciclo Completo del Sistema}
% Testo da inserire

\section{Query ed Esempi su Kibana}
% Testo da inserire

\section{Output Predittivo e Andamento Match}
% Testo da inserire

\section{Osservazioni e Coerenza dei Dati}
% Testo da inserire


% ===============================
% CAPITOLO 6 - Conclusioni
% ===============================

\chapter{Conclusioni e Sviluppi Futuri}

\section{Bilancio Finale e Competenze Sviluppate}
% Testo da inserire

\section{Estensioni e Sviluppi Futuri}
% Testo da inserire

\end{document}
